{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a786c77c",
   "metadata": {},
   "source": [
    "# LangChain: Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d673d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from L2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbff7257",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "chain = new_chain(llm, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db24677d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "The answer to 1+1 is 2.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Your name is Andrew, as you mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "print(chain(\"Hi, my name is Andrew\"))\n",
    "print(chain(\"What is 1+1?\"))\n",
    "print(chain(\"What is my name?\", verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2529400d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\\nHuman: What is 1+1?\\nAI: The answer to 1+1 is 2.\\nHuman: What is my name?\\nAI: Your name is Andrew, as you mentioned earlier.\"}\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI: Your name is Andrew, as you mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14219b70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n",
      "Human: Not much, just hanging\n",
      "AI: Cool\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    \"Hi\",\n",
    "    \"What's up\",\n",
    "    \"Not much, just hanging\",\n",
    "    \"Cool\",\n",
    "]\n",
    "memory = ConversationBufferMemory()\n",
    "add_buffer(memory, chat_history)\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98e9ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea6233e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Not much, just hanging\n",
      "AI: Cool\n"
     ]
    }
   ],
   "source": [
    "memory_window = ConversationBufferWindowMemory(k=1) \n",
    "add_buffer(memory_window, chat_history)\n",
    "print(memory_window.buffer)\n",
    "\n",
    "chain_window = new_chain(llm, memory_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4faaa952",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "The answer to 1+1 is 2.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm sorry, I don't have access to that information. Could you please tell me your name?\n"
     ]
    }
   ],
   "source": [
    "print(chain_window(\"Hi, my name is Andrew\"))\n",
    "print(chain_window(\"What is 1+1?\"))\n",
    "print(chain_window(\"What is my name?\", verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2931b92",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43582ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Amazing!\n",
      "Human: Backpropagation is what?\n",
      "AI: Beautiful!\n",
      "Human: Chatbots are what?\n",
      "AI: Charming!\n"
     ]
    }
   ],
   "source": [
    "memory_token = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "\n",
    "chat_history_v2 = [\n",
    "    \"AI is what?!\",\n",
    "    \"Amazing!\",\n",
    "    \"Backpropagation is what?\",\n",
    "    \"Beautiful!\",\n",
    "    \"Chatbots are what?\",\n",
    "    \"Charming!\",\n",
    "]\n",
    "\n",
    "add_buffer(memory_token, chat_history_v2)\n",
    "print(memory_token.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff55d5d",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a5b238f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human and AI exchange casual greetings before the human asks about their schedule for the day. The AI informs the human of a meeting with their product team at 8am, followed by time to work on their LangChain project, and a lunch meeting with a customer interested in the latest in AI. The AI emphasizes the importance of bringing their laptop to show the latest LLM demo.\n"
     ]
    }
   ],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "chat_history += [\n",
    "    \"What is on the schedule today?\",\n",
    "    schedule,\n",
    "]\n",
    "\n",
    "memory_sum = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "add_buffer(memory_sum, chat_history)\n",
    "print(memory_sum.buffer)\n",
    "chain_sum = new_chain(llm, memory_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a221b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange casual greetings before the human asks about their schedule for the day. The AI informs the human of a meeting with their product team at 8am, followed by time to work on their LangChain project, and a lunch meeting with a customer interested in the latest in AI. The AI emphasizes the importance of bringing their laptop to show the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the customer's interest in AI, I would recommend showcasing the latest features of our Language Learning Model (LLM). Specifically, you could demonstrate how LLM can accurately translate complex sentences from one language to another, or how it can identify and correct grammatical errors in real-time. Additionally, you could highlight the model's ability to learn and adapt to new languages and dialects, which sets it apart from other language learning tools on the market.\n"
     ]
    }
   ],
   "source": [
    "print(chain_sum(\"What would be a good demo to show?\", verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "947af8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange casual greetings before the human asks about their schedule for the day. The AI informs the human of a meeting with their product team at 8am, followed by time to work on their LangChain project, and a lunch meeting with a customer interested in the latest in AI. The AI emphasizes the importance of bringing their laptop to show the latest LLM demo. The human asks what would be a good demo to show.\n",
      "AI: Based on the customer's interest in AI, I would recommend showcasing the latest features of our Language Learning Model (LLM). Specifically, you could demonstrate how LLM can accurately translate complex sentences from one language to another, or how it can identify and correct grammatical errors in real-time. Additionally, you could highlight the model's ability to learn and adapt to new languages and dialects, which sets it apart from other language learning tools on the market.\n",
      "Human: What are the next steps to take?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "After the lunch meeting, we have a scheduled call with our investors to discuss the progress of our LangChain project. It would be important to have a clear update on the project's timeline and any potential roadblocks we may be facing. Additionally, we have a team brainstorming session in the afternoon to discuss new ideas for our AI product line. It would be helpful to come prepared with any ideas or suggestions you may have.\n"
     ]
    }
   ],
   "source": [
    "print(chain_sum(\"What are the next steps to take?\", verbose=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
